{"metadata":{"colab":{"collapsed_sections":["YCNTA_gUUbBD"],"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom matplotlib import pyplot as plt\nfrom scipy.io import loadmat\nfrom torchinfo import summary\n\nDATASET_DIR = \"/kaggle/input/bci-term-project/BCICIV_2a_gdf\"\nDATASET_DIR_TEST = \"/kaggle/input/bci-homework-3-kaggle-judge/BCI_hw3_dataset/labeled_test\"\nDATASET_DIR_EXAM = \"/kaggle/input/bci-homework-3-kaggle-judge/BCI_hw3_dataset/unlabeled_test\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"StIddDUdJ79U","execution":{"iopub.status.busy":"2023-05-26T14:44:56.783534Z","iopub.execute_input":"2023-05-26T14:44:56.784117Z","iopub.status.idle":"2023-05-26T14:44:56.795580Z","shell.execute_reply.started":"2023-05-26T14:44:56.784077Z","shell.execute_reply":"2023-05-26T14:44:56.794553Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## EEG Model","metadata":{"id":"pwJs0RL6KnFA"}},{"cell_type":"markdown","source":"### EEGNet","metadata":{"id":"IMFfCOTPLHT8"}},{"cell_type":"code","source":"class EEGNet(nn.Module):\n    \"\"\"EEGNet model from Lawhern et al 2018.\n    ... Parameters ............\n    C: int\n        Number of EEG input channels.\n    N: int\n        Number of EEG input time samples.\n    nb_classes: int\n        Number of classes to predict.\n    kernLength: int\n        Length of temporal convolution in first layer.\n    F1, F2: int\n        Number of temporal filters (F1) and number of pointwise filters (F2) to learn.\n    D: int\n        Number of spatial filters to learn within each temporal convolution.\n    dropoutRate: float\n        Dropout ratio.\n    ... References ............\n    https://arxiv.org/abs/1611.08024\n    \"\"\"\n\n    def __init__(self, C, N, nb_classes, kernLength=64, F1=8, F2=16, D=2, dropoutRate=0.5):\n        super(EEGNet, self).__init__()\n\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(1, F1, (1, kernLength), padding=\"valid\", bias=False),\n            nn.BatchNorm2d(F1, eps=1e-3, momentum=0.99)\n        )\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(\n                F1, D * F1, (C, 1), groups=F1, bias=False\n            ),\n            nn.BatchNorm2d(D * F1, eps=1e-3, momentum=0.99),\n            nn.ELU(),\n            nn.AvgPool2d((1, 4)),\n            nn.Dropout(dropoutRate)\n        )\n\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(\n                D * F1, D * F1, (1, 16),\n                padding=(0, 8), groups=D * F1, bias=False\n            ),\n            nn.Conv2d(D * F1, F2, (1, 1), bias=False),\n            nn.BatchNorm2d(F2, eps=1e-3, momentum=0.99),\n            nn.ELU(),\n            nn.AvgPool2d((1, 8)),\n            nn.Dropout(dropoutRate)\n        )\n\n        fc_inSize = self.get_size(C, N)[1]\n        self.classifier = nn.Linear(fc_inSize, nb_classes, bias=True)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = x.view(x.size()[0], -1)\n        x = self.classifier(x)\n        return x\n\n    def get_size(self, C, N):\n        data = torch.ones((1, 1, C, N))\n        x = self.conv1(data)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = x.view(x.size()[0], -1)\n        return x.size()\n","metadata":{"colab":{"background_save":true},"id":"vY2SM4vEKpwB","execution":{"iopub.status.busy":"2023-05-26T14:44:56.799693Z","iopub.execute_input":"2023-05-26T14:44:56.801020Z","iopub.status.idle":"2023-05-26T14:44:56.829743Z","shell.execute_reply.started":"2023-05-26T14:44:56.800984Z","shell.execute_reply":"2023-05-26T14:44:56.828932Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### ShallowConvNet","metadata":{"id":"-ayUlB9nLJfL"}},{"cell_type":"code","source":"class ShallowConvNet(nn.Module):\n    \"\"\"Shallow ConvNet model from Schirrmeister et al 2017.\n    ... Parameters ............\n    C: int\n        Number of EEG input channels.\n    N: int\n        Number of EEG input time samples.\n    nb_classes: int\n        Number of classes to predict.\n    NT: int\n        Number of temporal filters.\n    NS: int\n        Number of spatial filters.\n    tkerLen: int\n        Length of the temporal filter.\n    pool_tLen: int\n        Length of temporal pooling filter.\n    pool_tStep: int\n        Length of stride of temporal pooling filters.\n    batch_norm: bool\n        Whether to use batch normalization.\n    dropRate: float\n        Dropout ratio.\n    ... References ............\n    https://arxiv.org/abs/1703.05051\n    \"\"\"\n\n    def __init__(self, C, N, nb_classes, NT=40, NS=40, tkerLen=12, pool_tLen=35, pool_tStep=7, batch_norm=True,\n                 dropRate=0.25):\n        super(ShallowConvNet, self).__init__()\n\n        self.conv1 = nn.Conv2d(1, NT, (1, tkerLen), bias=False)\n        self.conv2 = nn.Conv2d(NT, NS, (C, 1), bias=False)\n        self.Bn1 = nn.BatchNorm2d(NS)\n        self.AvgPool1 = nn.AvgPool2d((1, pool_tLen), stride=(1, pool_tStep))\n        self.Drop1 = nn.Dropout(dropRate)\n        fc_inSize = self.get_size(C, N)[1]\n        self.classifier = nn.Linear(fc_inSize, nb_classes, bias=True)\n        self.batch_norm = batch_norm\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        if self.batch_norm:\n            x = self.Bn1(x)\n        x = x ** 2\n        x = self.AvgPool1(x)\n        x = torch.log(x)\n        x = self.Drop1(x)\n        x = x.view(x.size()[0], -1)\n        x = self.classifier(x)\n        return x\n\n    def get_size(self, C, N):\n        data = torch.ones((1, 1, C, N))\n        x = self.conv1(data)\n        x = self.conv2(x)\n        x = self.AvgPool1(x)\n        x = x.view(x.size()[0], -1)\n        return x.size()\n","metadata":{"colab":{"background_save":true},"id":"YSlhxwgpLL2R","execution":{"iopub.status.busy":"2023-05-26T14:44:56.834827Z","iopub.execute_input":"2023-05-26T14:44:56.836532Z","iopub.status.idle":"2023-05-26T14:44:56.857080Z","shell.execute_reply.started":"2023-05-26T14:44:56.836496Z","shell.execute_reply":"2023-05-26T14:44:56.856016Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### SCCNet","metadata":{"id":"rGf6cMA1LcTa"}},{"cell_type":"code","source":"# (Bonus) Optional TODO: Advanced SCCNet model without permutation layer\nclass SCCNet_v2(nn.Module):\n    \"\"\"Advanced SCCNet model without permutation layer.\n    ... Parameters ............\n    C: int\n        Number of EEG input channels.\n    N: int\n        Number of EEG input time samples.\n    nb_classes: int\n        Number of classes to predict.\n    Nu: int\n        Number of spatial kernel.\n    Nt: int\n        Length of spatial kernel.\n    Nc: int\n        Number of spatial-temporal kernel.\n    fs: float\n        Sampling frequency of EEG input.\n    dropoutRate: float\n        Dropout ratio.\n    ... References ............\n    https://ieeexplore.ieee.org/document/8716937\n    \"\"\"\n\n    def __init__(self, C, N, nb_classes, Nu=None, Nt=1, Nc=20, fs=1000.0, dropoutRate=0.5):\n        super(SCCNet_v2, self).__init__()\n        Nu = C if Nu is None else Nu\n        self.conv1 = nn.Conv2d(1, 1, (1, Nt), bias=False)\n        self.bn1 = nn.BatchNorm2d(num_features=1)\n        self.relu1 = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(1, Nc, (Nu, int(fs * 0.1)), bias=False)\n        self.bn2 = nn.BatchNorm2d(num_features=Nc)\n        self.relu2 = nn.ReLU(inplace=True)\n\n        self.dropout = nn.Dropout(p=dropoutRate)\n        # Pooling block\n        self.avgpool = nn.AvgPool2d(kernel_size=(1, int(fs * 0.5)), stride=(1, int(fs * 0.1)))\n\n        # get linear size\n        fc_inSize = self.get_size(C, N)[1]\n        self.classifier = nn.Linear(fc_inSize, nb_classes, bias=True)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.dropout(x)\n\n        # Second convolution block\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = x ** 2\n\n        # Pooling block\n        x = self.avgpool(x)\n        x = self.dropout(x)\n\n        # Softmax block\n        x = x.view(x.size()[0], -1)\n        x = self.classifier(x)\n        return x\n\n    def get_size(self, C, N):\n        data = torch.ones((1, 1, C, N))\n        x = self.conv1(data)\n        x = self.conv2(x)\n        x = self.avgpool(x)\n        x = x.view(x.size()[0], -1)\n        return x.size()\n","metadata":{"colab":{"background_save":true},"id":"oM_OywrgyhvZ","execution":{"iopub.status.busy":"2023-05-26T14:44:56.863247Z","iopub.execute_input":"2023-05-26T14:44:56.863823Z","iopub.status.idle":"2023-05-26T14:44:56.883013Z","shell.execute_reply.started":"2023-05-26T14:44:56.863789Z","shell.execute_reply":"2023-05-26T14:44:56.882114Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# TODO: finish the SCCNet\nclass SCCNet(nn.Module):\n    \"\"\"SCCNet model from Wei et al 2019.\n    Note: Nc was misused in the paper to describe both the number of EEG input channels and the number of spatial-temporal kernel.\n    Please refer to the following description to find the correspondence of the defined parameters and noataions in the paper.\n    ... Parameters ............\n    C: int\n        Number of EEG input channels. (Same as the Nc mentioned in the first and second paragraphs of the paper section II.B)\n    N: int\n        Number of EEG input time samples.\n    nb_classes: int\n        Number of classes to predict.\n    Nu: int\n        Number of spatial kernel.\n    Nt: int\n        Length of spatial kernel.\n    Nc: int\n        Number of spatial-temporal kernel. (Same as the Nc mentioned in the third paragraph of the paper section II.B)\n    fs: float\n        Sampling frequency of EEG input.\n    dropoutRate: float\n        Dropout ratio.\n    ... References ............\n    https://ieeexplore.ieee.org/document/8716937\n    \"\"\"\n\n    # You can only add extra argument to this function, do NOT remove the existed arguments\n    # The model structure should be dynamic changed by the provided arguments,\n    # There will be a score penalty if SCCNet structure is static\n    def __init__(self, C, N, nb_classes, Nu=None, Nt=1, Nc=20, fs=1000.0, dropoutRate=0.5):\n        super(SCCNet, self).__init__()\n        Nu = C if Nu is None else Nu\n        self.conv1 = nn.Conv2d(1, Nu, (C, Nt), bias=False)\n        self.bn1 = nn.BatchNorm2d(num_features=1)\n        self.relu1 = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(1, Nc, (Nu, int(fs * 0.1)), bias=False)\n        self.bn2 = nn.BatchNorm2d(num_features=Nc)\n        self.relu2 = nn.ReLU(inplace=True)\n\n        self.dropout = nn.Dropout(p=dropoutRate)\n        # Pooling block\n        self.avgpool = nn.AvgPool2d(kernel_size=(1, int(fs * 0.5)), stride=(1, int(fs * 0.1)))\n\n        # get linear size\n        fc_inSize = self.get_size(C, N)[1]\n        self.classifier = nn.Linear(fc_inSize, nb_classes, bias=True)\n\n    def forward(self, x):\n\n        # First convolution block\n        x = self.conv1(x)\n        x = x.permute(0, 2, 1, 3)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.dropout(x)\n\n        # Second convolution block\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = x ** 2\n\n        # Pooling block\n        x = self.avgpool(x)\n        x = self.dropout(x)\n\n        # Softmax block\n        x = x.view(x.size()[0], -1)\n        x = self.classifier(x)\n        return x\n\n    def get_size(self, C, N):\n        data = torch.ones((1, 1, C, N))\n        x = self.conv1(data)\n        x = x.permute(0, 2, 1, 3)\n        x = self.conv2(x)\n        x = self.avgpool(x)\n        x = x.view(x.size()[0], -1)\n        return x.size()\n\n\nclass Permute2d(nn.Module):\n    def __init__(self, shape):\n        super(Permute2d, self).__init__()\n        self.shape = shape\n\n    def forward(self, x):\n        return torch.permute(x, self.shape)","metadata":{"colab":{"background_save":true},"id":"796ap3tDLd7g","execution":{"iopub.status.busy":"2023-05-26T14:44:56.933139Z","iopub.execute_input":"2023-05-26T14:44:56.933606Z","iopub.status.idle":"2023-05-26T14:44:56.954549Z","shell.execute_reply.started":"2023-05-26T14:44:56.933572Z","shell.execute_reply":"2023-05-26T14:44:56.953621Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"id":"GMAXhwg4L6kl"}},{"cell_type":"code","source":"# config training scheme, mode, hyperparam\neegmodel_name = \"SCCNet\"\neegmodel = SCCNet  # function alias, should be EEGNet, ShallowConvNet, SCCNet, SCCNet_v2\nkwargs = dict(fs=125.0, dropoutRate=0.5)  # custom args for different EEG model\nscheme = \"si\"  # \"ind\", \"si\", \"sd\", \"sift\"\nepochs = 200\nbatch_size = 16\nlr = 1e-3\nsavepath = \"/kaggle/working/checkpoints\"\nos.makedirs(savepath, exist_ok=True)\n\nsubject_id = 6","metadata":{"id":"FM0GyQJGSxGw","execution":{"iopub.status.busy":"2023-05-26T14:44:56.955942Z","iopub.execute_input":"2023-05-26T14:44:56.957501Z","iopub.status.idle":"2023-05-26T14:44:56.972224Z","shell.execute_reply.started":"2023-05-26T14:44:56.957469Z","shell.execute_reply":"2023-05-26T14:44:56.971110Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### load data","metadata":{"id":"YCNTA_gUUbBD"}},{"cell_type":"code","source":"mat_T = loadmat(os.path.join(DATASET_DIR, f\"A0{subject_id}T_output.mat\"))\nmat_label = loadmat(os.path.join(DATASET_DIR, f\"A0{subject_id}T.mat\"))\nx_data, y_data = mat_T[\"data\"], mat_label[\"classlabel\"].squeeze()\nx_train = np.zeros((0, *x_data.shape[1:]), dtype=x_data.dtype)\ny_train = np.zeros((0,), dtype=y_data.dtype)\nx_valid = np.zeros((0, *x_data.shape[1:]), dtype=x_data.dtype)\ny_valid = np.zeros((0,), dtype=y_data.dtype)\n\nfor sub_id in range(1, 10):\n    if sub_id == subject_id:\n        continue\n    mat_T = loadmat(os.path.join(DATASET_DIR, f\"A0{sub_id}T_output.mat\"))\n    mat_label = loadmat(os.path.join(DATASET_DIR, f\"A0{sub_id}T.mat\"))\n    x_data, y_data = mat_T[\"data\"], mat_label[\"classlabel\"].squeeze()\n    for c in range(1, 5):\n        x_, y_ = x_data[y_data == c], y_data[y_data == c]\n        ## if subject_id==select_test don't add,else add 75% to train 25% to validation\n        x_train = np.append(x_train, x_[:54], axis=0)\n        y_train = np.append(y_train, y_[:54], axis=0)\n        x_valid = np.append(x_valid, x_[54:], axis=0)\n        y_valid = np.append(y_valid, y_[54:], axis=0)\n\nfor sub_id in range(1, 10):\n    if sub_id == subject_id:\n        continue\n    mat_T = loadmat(os.path.join(DATASET_DIR, f\"A0{sub_id}E_output.mat\"))\n    mat_label = loadmat(os.path.join(DATASET_DIR, f\"A0{sub_id}E.mat\"))\n    x_data, y_data = mat_T[\"data\"], mat_label[\"classlabel\"].squeeze()\n    for c in range(1, 5):\n        x_, y_ = x_data[y_data == c], y_data[y_data == c]\n        ## if subject_id==select_test don't add,else add 75% to train 25% to validation\n        x_train = np.append(x_train, x_[:54], axis=0)\n        y_train = np.append(y_train, y_[:54], axis=0)\n        x_valid = np.append(x_valid, x_[54:], axis=0)\n        y_valid = np.append(y_valid, y_[54:], axis=0)\n\n# numpy array to tensor \nx_train = torch.from_numpy(x_train)\ny_train = torch.from_numpy(y_train).long()\nx_valid = torch.from_numpy(x_valid)\ny_valid = torch.from_numpy(y_valid).long()\n\n# tensor reshape for training\nx_train = x_train.unsqueeze(1)\ny_train = y_train - 1\ny_train = F.one_hot(y_train, 4)\n\nx_valid = x_valid.unsqueeze(1)\ny_valid = y_valid - 1\ny_valid = F.one_hot(y_valid, 4)\n\n\nprint(\"train: {}, {}\".format(x_train.size(), y_train.size()))\nprint(\"valid: {}, {}\".format(x_valid.size(), y_valid.size()))\n\n# build training and validation dataloader\ntrainset = torch.utils.data.TensorDataset(x_train, y_train)\nvalidset = torch.utils.data.TensorDataset(x_valid, y_valid)\ntra_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\nval_loader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True, num_workers=2)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3J5MaTR8Tmrh","outputId":"695c5eb2-9f5e-49d8-e317-b6476d50d24c","execution":{"iopub.status.busy":"2023-05-26T14:44:56.974677Z","iopub.execute_input":"2023-05-26T14:44:56.975211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### training stage","metadata":{"id":"tQsP7kEwf2rc"}},{"cell_type":"code","source":"# train an epoch, evaluate an epoch\n# if you are familiar with Pytorch, you CAN custom these function\n#  such as adding the lr_scheduler to optimize the training progress\n\ndef train_an_epoch(model, data_loader, loss_fn, optimizer):\n    model.train()\n\n    a, b = 0, 0  # hit sample, total sample\n    epoch_loss = np.zeros((len(data_loader),))\n    for i, (x_batch, y_batch) in enumerate(data_loader):\n        x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        output = model(x_batch) \n        loss = loss_fn(output, y_batch)  \n        ## L2_regularization\n        l2_lambda = 0.0001\n        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n        loss += l2_lambda * l2_norm\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss[i] = loss.item()\n        b += y_batch.size(0)\n        a += torch.sum(y_batch.argmax(dim=1) == output.argmax(dim=1)).item()\n    return epoch_loss.mean(), a / b  # return the loss and acc\n\n\ndef evaluate_an_epoch(model, data_loader, loss_fn):\n    \n    for m in model.modules():\n        for child in m.children():\n            if type(child) == nn.BatchNorm2d:\n                child.track_running_stats = False\n                child.running_mean = None\n                child.running_var = None\n                \n    model.eval()\n    a, b = 0, 0  # hit sample, total sample\n    epoch_loss = np.zeros((len(data_loader),))\n    for i, (x_batch, y_batch) in enumerate(data_loader):\n        x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device, dtype=torch.float)\n        output = model(x_batch)  \n        loss = loss_fn(output, y_batch) \n\n        epoch_loss[i] = loss.item()\n        b += y_batch.size(0)\n        a += torch.sum(y_batch.argmax(dim=1) == output.argmax(dim=1)).item()\n    return epoch_loss.mean(), a / b  # return the loss and acc","metadata":{"id":"0_c1O8LyiB5d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if eegmodel_name==\"EEGNet\" or eegmodel_name==\"ShallowConvNet\":\n    model = eegmodel(x_train.size(2), x_train.size(3), 4)  # EEGNet, ShallowConvNet\nelif eegmodel_name==\"SCCNet\" or eegmodel_name==\"SCCNet_v2\":\n    model = eegmodel(x_train.size(2), x_train.size(3), 4, **kwargs) # SCCNet\n    \nloss_fn = nn.CrossEntropyLoss()  # loss function, can be modified\nopt_fn = torch.optim.Adam(model.parameters(), lr=lr)  # optimizer, CAN be modified\n\n# dump the model structure\nsummary(model, input_size=(batch_size, *list(x_train.size()[1:])))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCWC0hCVrEad","outputId":"b2bbd47d-ca24-40f0-97e7-f204472378e6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if you are familiar with Pytorch, you CAN custom the following training loop\n\nhist = dict(\n    loss=np.zeros((epochs,)), val_loss=np.zeros((epochs,)),\n    acc=np.zeros((epochs,)), val_acc=np.zeros((epochs,))\n)\nclock_ini = time.time()\nfor ep in range(epochs):\n    loss, acc = train_an_epoch(model, tra_loader, loss_fn, opt_fn)\n    val_loss, val_acc = evaluate_an_epoch(model, val_loader, loss_fn)\n    print(\"Epoch {}: loss={:.4f}, acc={:.4f}, val_loss={:.4f}, val_acc={:.4f}\".format(ep, loss, acc, val_loss, val_acc))\n    hist[\"loss\"][ep] = loss\n    hist[\"acc\"][ep] = acc\n    hist[\"val_loss\"][ep] = val_loss\n    hist[\"val_acc\"][ep] = val_acc\n\n    if True:\n        # save the pre-trained weight in each epoch, CAN be modified\n        checkpoint = dict(epoch=-1, state_dict=model.state_dict(), loss=loss, val_loss=val_loss)\n        torch.save(checkpoint, os.path.join(savepath, f\"{eegmodel_name}_MODEL-ep{ep}.pth\"))\nprint(\"time spend: {:.2f} sec\".format(time.time() - clock_ini))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Vc2hyIUf4-n","outputId":"7d92204a-d6a9-4c1b-fde5-5e5b75296937","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Acc curve, Loss curve\nplt.figure(figsize=(10, 4))\nplt.subplot(1, 2, 1)\nplt.title(\"Acc Curve\")\nplt.plot(hist[\"acc\"], color=\"red\")\nplt.plot(hist[\"val_acc\"], color=\"blue\")\nplt.subplot(1, 2, 2)\nplt.title(\"Loss Curve\")\nplt.plot(hist[\"loss\"], color=\"red\")\nplt.plot(hist[\"val_loss\"], color=\"blue\")\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"5uyzf16TtdIu","outputId":"7b6cc417-8443-4422-d71f-d5e4b4229d5c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{"id":"UHAmdMQ5tD2D"}},{"cell_type":"code","source":"# load pre-trained model\n\nbest_epoch = hist[\"val_loss\"].argmin()  # TODO: determine the `BEST` epoch\nprint(best_epoch)\ntest_model_path = os.path.join(savepath, \"{}_MODEL-ep{}.pth\".format(eegmodel_name, best_epoch))\ncheckpoint = torch.load(test_model_path, map_location=\"cpu\")  # load .pth\nmodel.load_state_dict(checkpoint[\"state_dict\"])  # set model weight\n\n# testing on subject S01 test (E) session\nmat = loadmat(os.path.join(DATASET_DIR, f\"A0{subject_id}E_output.mat\"))\nmat_label = loadmat(os.path.join(DATASET_DIR, f\"A0{subject_id}E.mat\"))\nx, y = mat[\"data\"], mat_label[\"classlabel\"].squeeze()\n\nx = torch.from_numpy(x)\ny = torch.from_numpy(y).long()\nx = x.unsqueeze(1)\n\ny = y - 1\nprint(np.unique(y))\ny = F.one_hot(y, 4)\n\nprint(\"test: {}, {}\".format(x.size(), y.size()))\n\ntestset = torch.utils.data.TensorDataset(x, y)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\nloss, acc = evaluate_an_epoch(model, test_loader, loss_fn)\nprint(loss, round(acc, 14))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NnywQNwL7pQ","outputId":"608207ab-901d-4f21-9dd7-934d7b61085a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Analyzing\nYou need to do some further analysis including\n- confusion matrix, \n- topographic maps for spatial kernel weights in SCCNet\n\nYou need to do these on your own in this section","metadata":{"id":"_6ou77S3zpXS"}},{"cell_type":"code","source":"def evaluate_an_epoch_pred(model, data_loader, loss_fn):\n    model.eval()\n    a, b = 0, 0  # hit sample, total sample\n    epoch_loss = np.zeros((len(data_loader),))\n    pred = []\n    labels = []\n    for i, (x_batch, y_batch) in enumerate(data_loader):\n        x_batch, y_batch = x_batch.to(device, dtype=torch.float), y_batch.to(device, dtype=torch.float)\n        output = model(x_batch)\n        output_np = output.detach().cpu().numpy()\n        ## save the label and prediction\n        for p in output_np:\n            pred.append(np.argmax(p))\n        label = y_batch.detach().cpu().numpy()\n        \n        for l in label:\n            labels.append(np.argmax(l))\n            \n        loss = loss_fn(output, y_batch)\n        epoch_loss[i] = loss.item()\n        b += y_batch.size(0)\n        a += torch.sum(y_batch.argmax(dim=1) == output.argmax(dim=1)).item()\n    return epoch_loss.mean(), a / b, pred, labels  # return the loss and acc\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mne doc: https://mne.tools/stable/python_reference.html\n# \"data_detail.json\" in BCI_hw3_dataset/ provides you with all channel names in this dataset. It will help you to plot a topoplot.\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\n\n## use evaluate that can return prediction and true label\ncur_loss, cur_acc, cur_pred, cur_label = evaluate_an_epoch_pred(model, test_loader, loss_fn)\n\n## construct a confusion matrix\nprint(f'Accuracy on subject {subject_id}: {round(cur_acc, 4)}')\ncm = confusion_matrix(cur_label, cur_pred)\nplt.imshow(cm, interpolation='nearest', cmap=plt.get_cmap('Blues'))\nplt.colorbar()\ntick_marks = np.arange(len(np.unique(cur_label)))\nplt.xticks(tick_marks, np.unique(cur_label))\nplt.yticks(tick_marks, np.unique(cur_label))\n## add the number on the graph\nthresh = cm.max() / 2.\nfor i, j in np.ndindex(cm.shape):\n    plt.text(j, i, format(cm[i, j], 'd'),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"id":"E-0XIkvG01TD","trusted":true},"execution_count":null,"outputs":[]}]}